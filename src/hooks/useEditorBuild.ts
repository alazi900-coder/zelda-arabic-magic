import { useState, useRef, useEffect } from "react";
import type { IntegrityCheckResult } from "@/components/editor/IntegrityCheckDialog";
import { idbGet } from "@/lib/idb-storage";
import { processArabicText, hasArabicChars as hasArabicCharsProcessing, hasArabicPresentationForms, removeArabicPresentationForms, reverseBidi } from "@/lib/arabic-processing";
import { EditorState, hasTechnicalTags, restoreTagsLocally } from "@/components/editor/types";
import { BuildPreview } from "@/components/editor/BuildConfirmDialog";
import type { MutableRefObject } from "react";

export interface BuildStats {
  modifiedCount: number;
  expandedCount: number;
  fileSize: number;
  compressedSize?: number;
  avgBytePercent: number;
  maxBytePercent: number;
  longest: { key: string; bytes: number } | null;
  shortest: { key: string; bytes: number } | null;
  categories: Record<string, { total: number; modified: number }>;
}

export interface BdatFileStat {
  fileName: string;
  total: number;
  translated: number;
  hasError?: boolean;
}

interface UseEditorBuildProps {
  state: EditorState | null;
  setState: React.Dispatch<React.SetStateAction<EditorState | null>>;
  setLastSaved: (msg: string) => void;
  arabicNumerals: boolean;
  mirrorPunctuation: boolean;
  gameType?: string;
  forceSaveRef?: React.RefObject<() => Promise<void>>;
}

export function useEditorBuild({ state, setState, setLastSaved, arabicNumerals, mirrorPunctuation, gameType, forceSaveRef }: UseEditorBuildProps) {
  // Use a ref to always access the LATEST state in async handlers
  const stateRef = useRef(state);
  useEffect(() => { stateRef.current = state; }, [state]);

  const [building, setBuilding] = useState(false);
  const [buildProgress, setBuildProgress] = useState("");
  const [applyingArabic, setApplyingArabic] = useState(false);
  const [buildStats, setBuildStats] = useState<BuildStats | null>(null);
  const [buildPreview, setBuildPreview] = useState<BuildPreview | null>(null);
  const [showBuildConfirm, setShowBuildConfirm] = useState(false);
  const [bdatFileStats, setBdatFileStats] = useState<BdatFileStat[]>([]);
  const [integrityResult, setIntegrityResult] = useState<IntegrityCheckResult | null>(null);
  const [showIntegrityDialog, setShowIntegrityDialog] = useState(false);
  const [checkingIntegrity, setCheckingIntegrity] = useState(false);


  const handleApplyArabicProcessing = () => {
    const currentState = stateRef.current;
    if (!currentState) return;
    setApplyingArabic(true);
    const newTranslations = { ...currentState.translations };
    let processedCount = 0, skippedCount = 0;
    for (const [key, value] of Object.entries(newTranslations)) {
      if (!value?.trim()) continue;
      if (hasArabicPresentationForms(value)) { skippedCount++; continue; }
      if (!hasArabicCharsProcessing(value)) continue;
      newTranslations[key] = processArabicText(value, { arabicNumerals, mirrorPunct: mirrorPunctuation });
      processedCount++;
    }
    setState(prev => prev ? { ...prev, translations: newTranslations } : null);
    setApplyingArabic(false);
    setLastSaved(`âœ… ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¹Ù„Ù‰ ${processedCount} Ù†Øµ` + (skippedCount > 0 ? ` (ØªÙ… ØªØ®Ø·ÙŠ ${skippedCount} Ù†Øµ Ù…Ø¹Ø§Ù„Ø¬ Ù…Ø³Ø¨Ù‚Ø§Ù‹)` : ''));
    setTimeout(() => setLastSaved(""), 5000);
  };

  const handleUndoArabicProcessing = () => {
    const currentState = stateRef.current;
    if (!currentState) return;
    setApplyingArabic(true);
    const newTranslations = { ...currentState.translations };
    let revertedCount = 0;
    for (const [key, value] of Object.entries(newTranslations)) {
      if (!value?.trim()) continue;
      if (!hasArabicPresentationForms(value)) continue;
      // Reverse BiDi (self-inverse) then map presentation forms back to standard
      const unReversed = reverseBidi(value);
      newTranslations[key] = removeArabicPresentationForms(unReversed);
      newTranslations[key] = removeArabicPresentationForms(unReversed);
      revertedCount++;
    }
    setState(prev => prev ? { ...prev, translations: newTranslations } : null);
    setApplyingArabic(false);
    setLastSaved(`â†©ï¸ ØªÙ… Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¹Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù€ ${revertedCount} Ù†Øµ`);
    setTimeout(() => setLastSaved(""), 5000);
  };

  const handlePreBuild = async () => {
    const currentState = stateRef.current;
    if (!currentState) return;
    
    // Force-save before preview too
    if (forceSaveRef?.current) {
      await forceSaveRef.current();
    }

    const nonEmptyTranslations: Record<string, string> = {};
    for (const [k, v] of Object.entries(currentState.translations)) {
      if (v.trim()) nonEmptyTranslations[k] = v;
    }

    const protectedCount = Array.from(currentState.protectedEntries || []).filter(k => nonEmptyTranslations[k]).length;
    const normalCount = Object.keys(nonEmptyTranslations).length - protectedCount;

    // Category breakdown
    const categories: Record<string, number> = {};
    for (const key of Object.keys(nonEmptyTranslations)) {
      const parts = key.split(':')[0].split('/');
      const cat = parts.length > 1 ? parts[0] : 'Other';
      categories[cat] = (categories[cat] || 0) + 1;
    }

    // Compute warnings
    let overflowCount = 0;
    let unprocessedArabicCount = 0;
    const arabicRegex = /[\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF]/;
    const formsRegex = /[\uFB50-\uFDFF\uFE70-\uFEFF]/;

    for (const entry of currentState.entries) {
      const key = `${entry.msbtFile}:${entry.index}`;
      const trans = nonEmptyTranslations[key];
      if (!trans) continue;

      // Check byte overflow
      if (entry.maxBytes > 0) {
        const byteLen = new TextEncoder().encode(trans).length;
        if (byteLen > entry.maxBytes) overflowCount++;
      }

      // Check unprocessed Arabic
      if (arabicRegex.test(trans) && !formsRegex.test(trans)) {
        unprocessedArabicCount++;
      }
    }

    // Check if real files are loaded
    const bdatBinaryFileNames = await idbGet<string[]>("editorBdatBinaryFileNames");
    const hasBdatFiles = !!(bdatBinaryFileNames && bdatBinaryFileNames.length > 0);
    const isDemo = currentState.isDemo === true;

    // Count affected BDAT files
    let affectedFileCount = 0;
    if (hasBdatFiles && bdatBinaryFileNames) {
      for (const fileName of bdatBinaryFileNames) {
        const prefix = `bdat-bin:${fileName}:`;
        if (Object.keys(nonEmptyTranslations).some(k => k.startsWith(prefix))) {
          affectedFileCount++;
        }
      }
    }

    const sampleKeys = Object.keys(nonEmptyTranslations).slice(0, 10);

    console.log('[BUILD-PREVIEW] Total translations:', Object.keys(nonEmptyTranslations).length);
    console.log('[BUILD-PREVIEW] Overflow:', overflowCount, 'Unprocessed Arabic:', unprocessedArabicCount);
    console.log('[BUILD-PREVIEW] BDAT files:', affectedFileCount, 'isDemo:', isDemo);

    setBuildPreview({
      totalTranslations: Object.keys(nonEmptyTranslations).length,
      protectedCount,
      normalCount,
      categories,
      sampleKeys,
      overflowCount,
      unprocessedArabicCount,
      hasBdatFiles,
      isDemo,
      affectedFileCount,
    });
    setShowBuildConfirm(true);
  };

  const handleBuildXenoblade = async () => {
    // Always use the LATEST state via ref to avoid stale closures
    const currentState = stateRef.current;
    if (!currentState) return;
    // Close the build confirm dialog so progress messages are visible
    setShowBuildConfirm(false);
    // Force-save to IDB before reading data â€” prevents race condition with autosave
    if (forceSaveRef?.current) {
      await forceSaveRef.current();
    }
    setBuilding(true); setBuildProgress("ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØªØ±Ø¬Ù…Ø§Øª...");
    try {
      const msbtFiles = await idbGet<Record<string, ArrayBuffer>>("editorMsbtFiles");
      const msbtFileNames = await idbGet<string[]>("editorMsbtFileNames");
      const bdatFiles = await idbGet<Record<string, string>>("editorBdatFiles");
      const bdatFileNames = await idbGet<string[]>("editorBdatFileNames");
      const bdatBinaryFiles = await idbGet<Record<string, ArrayBuffer>>("editorBdatBinaryFiles");
      const bdatBinaryFileNames = await idbGet<string[]>("editorBdatBinaryFileNames");

      const hasMsbt = msbtFiles && msbtFileNames && msbtFileNames.length > 0;
      const hasBdat = bdatFiles && bdatFileNames && bdatFileNames.length > 0;
      const hasBdatBinary = bdatBinaryFiles && bdatBinaryFileNames && bdatBinaryFileNames.length > 0;

      if (!hasMsbt && !hasBdat && !hasBdatBinary) {
        setBuildProgress("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª.");
        setBuilding(false);
        return;
      }

      // Process binary BDAT files locally
      let localBdatResults: { name: string; data: Uint8Array }[] = [];
      let localModifiedCount = 0;
      const newBdatFileStats: BdatFileStat[] = [];
      const allOverflowErrors: { fileName: string; key: string; originalBytes: number; translationBytes: number; reason?: string; newOffset?: number }[] = [];

      if (hasBdatBinary) {
        setBuildProgress("Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„ÙØ§Øª BDAT Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ© Ù…Ø­Ù„ÙŠØ§Ù‹...");
        const { parseBdatFile } = await import("@/lib/bdat-parser");
        const { patchBdatFile } = await import("@/lib/bdat-writer");
        const { unhashLabel } = await import("@/lib/bdat-hash-dictionary");
        const { processArabicText, hasArabicPresentationForms: hasPF } = await import("@/lib/arabic-processing");

        const nonEmptyTranslations: Record<string, string> = {};
        for (const [k, v] of Object.entries(currentState.translations)) { if (v.trim()) nonEmptyTranslations[k] = v; }
        
        const totalKeys = Object.keys(currentState.translations).length;
        const nonEmptyCount = Object.keys(nonEmptyTranslations).length;
        setBuildProgress(`ğŸ“Š ÙˆØ¬Ø¯Øª ${nonEmptyCount} ØªØ±Ø¬Ù…Ø© Ù…Ù† Ø£ØµÙ„ ${totalKeys} Ù…ÙØªØ§Ø­...`);
        await new Promise(r => setTimeout(r, 200));
        console.log('[BUILD] âœ… State has', totalKeys, 'total keys,', nonEmptyCount, 'non-empty');
        
        if (nonEmptyCount === 0) {
          setBuildProgress(`âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ±Ø¬Ù…Ø§Øª! ØªØ£ÙƒØ¯ Ù…Ù† ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ Ø£ÙˆÙ„Ø§Ù‹. (${totalKeys} Ù…ÙØªØ§Ø­ Ø¨Ø¯ÙˆÙ† ØªØ±Ø¬Ù…Ø§Øª)`);
          setBuilding(false);
          return;
        }

        // Auto Arabic processing before build
        let autoProcessedCountBin = 0;
        // Strip newlines from bubble dialogue files (tlk, fev, cq) â€” game engine hides text with \n in bubbles
        const BUBBLE_FILE_PATTERNS = /(?:^|[:/])(?:tlk_|fev_|cq_)/i;
        let strippedNewlineCount = 0;
        for (const [key, value] of Object.entries(nonEmptyTranslations)) {
          if (!value?.trim()) continue;
          // Strip \n from bubble dialogue files
          if (value.includes('\n') && BUBBLE_FILE_PATTERNS.test(key)) {
            nonEmptyTranslations[key] = value.replace(/\n/g, ' ');
            strippedNewlineCount++;
          }
          const current = nonEmptyTranslations[key];
          if (hasArabicPresentationForms(current)) continue;
          if (!hasArabicCharsProcessing(current)) continue;
          nonEmptyTranslations[key] = processArabicText(current, { arabicNumerals, mirrorPunct: mirrorPunctuation });
          autoProcessedCountBin++;
        }
        if (strippedNewlineCount > 0) {
          setBuildProgress(`ğŸ«§ Ø¥Ø²Ø§Ù„Ø© ÙÙˆØ§ØµÙ„ Ø£Ø³Ø·Ø± Ù…Ù† ${strippedNewlineCount} Ù†Øµ ÙÙ‚Ø§Ø¹ÙŠ (tlk/fev/cq)...`);
          await new Promise(r => setTimeout(r, 200));
        }
        if (autoProcessedCountBin > 0) {
          setBuildProgress(`âœ… ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© ${autoProcessedCountBin} Ù†Øµ Ø¹Ø±Ø¨ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹...`);
          await new Promise(r => setTimeout(r, 200));
        }

      // Pre-scan: build per-file index of translations for O(1) lookup
      const perFileTranslations = new Map<string, Map<string, string>>();
      const perFileLegacy = new Map<string, Map<string, string>>();
      for (const [key, trans] of Object.entries(nonEmptyTranslations)) {
        if (key.startsWith('bdat-bin:')) {
          const secondColon = key.indexOf(':', 9);
          if (secondColon === -1) continue;
          const fName = key.slice(9, secondColon);
          const rest = key.slice(secondColon + 1);
          const lastColon = rest.lastIndexOf(':');
          if (lastColon === -1) continue;
          const mapKey = rest.slice(0, lastColon);
          if (mapKey.split(':').length < 3) continue;
          if (!perFileTranslations.has(fName)) perFileTranslations.set(fName, new Map());
          perFileTranslations.get(fName)!.set(mapKey, trans);
        } else if (key.startsWith('bdat:')) {
          const secondColon = key.indexOf(':', 5);
          if (secondColon === -1) continue;
          const fName = key.slice(5, secondColon);
          if (!perFileLegacy.has(fName)) perFileLegacy.set(fName, new Map());
          perFileLegacy.get(fName)!.set(key, trans);
        }
      }

      const filesWithTranslations = new Set([...perFileTranslations.keys(), ...perFileLegacy.keys()]);
      const filesToBuild = bdatBinaryFileNames!.filter(f => filesWithTranslations.has(f));
      const skippedCount = bdatBinaryFileNames!.length - filesToBuild.length;
      if (skippedCount > 0) {
        setBuildProgress(`â­ï¸ ØªØ®Ø·ÙŠ ${skippedCount} Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† ØªØ±Ø¬Ù…Ø§ØªØŒ Ø¨Ù†Ø§Ø¡ ${filesToBuild.length} Ù…Ù„Ù ÙÙ‚Ø·...`);
        await new Promise(r => setTimeout(r, 300));
      }

      // Process files in batches to keep UI responsive
      const BUILD_BATCH = 5;
      for (let batchStart = 0; batchStart < filesToBuild.length; batchStart += BUILD_BATCH) {
        const batchEnd = Math.min(batchStart + BUILD_BATCH, filesToBuild.length);
        setBuildProgress(`âš™ï¸ Ø¨Ù†Ø§Ø¡ ${batchStart + 1}-${batchEnd} Ù…Ù† ${filesToBuild.length} Ù…Ù„Ù...`);

        for (let fi = batchStart; fi < batchEnd; fi++) {
          const fileName = filesToBuild[fi];
          const buf = bdatBinaryFiles![fileName];
          if (!buf) continue;
          try {
            const data = new Uint8Array(buf);
            const bdatFile = parseBdatFile(data, unhashLabel);

            const translationMap = new Map<string, string>();

            // Use pre-indexed translations â€” no scanning needed
            const fileTransMap = perFileTranslations.get(fileName);
            if (fileTransMap) {
              for (const [mapKey, trans] of fileTransMap) {
                const processed = hasPF(trans) ? trans : processArabicText(trans, { arabicNumerals, mirrorPunct: mirrorPunctuation });
                translationMap.set(mapKey, processed);
              }
            }

            // Legacy fallback
            if (translationMap.size === 0) {
              const legacyMap = perFileLegacy.get(fileName);
              if (legacyMap && legacyMap.size > 0) {
                const { extractBdatStrings } = await import("@/lib/bdat-parser");
                const extractedStrings = extractBdatStrings(bdatFile, fileName);
                for (let i = 0; i < extractedStrings.length; i++) {
                  const s = extractedStrings[i];
                  const stateKey = `bdat:${fileName}:${i}`;
                  const trans = legacyMap.get(stateKey);
                  if (!trans) continue;
                  const processed = hasPF(trans) ? trans : processArabicText(trans, { arabicNumerals, mirrorPunct: mirrorPunctuation });
                  translationMap.set(`${s.tableName}:${s.rowIndex}:${s.columnName}`, processed);
                  localModifiedCount++;
                }
              }
            }

            // Record per-file stats (use translationMap size instead of expensive re-parse)
            newBdatFileStats.push({
              fileName,
              total: translationMap.size, // approximate â€” avoids costly extractBdatStrings
              translated: translationMap.size,
            });

            if (translationMap.size > 0) {
              const { result: patched, overflowErrors, patchedCount, skippedCount: patchSkipped, tableStats } = patchBdatFile(bdatFile, translationMap);
              localBdatResults.push({ name: fileName, data: patched });
              for (const e of overflowErrors) {
                allOverflowErrors.push({ fileName, ...e });
              }
              const u16Tables = tableStats.filter(ts => ts.hasU16Columns && ts.stringsSkipped > 0);
              if (u16Tables.length > 0) {
                console.warn(`[BUILD-BDAT] ${fileName}: ${u16Tables.length} u16 overflow tables`);
              }
              localModifiedCount += patchedCount;
            } else {
              localBdatResults.push({ name: fileName, data });
            }
          } catch (e) {
            console.warn(`Failed to rebuild BDAT ${fileName}:`, e);
            newBdatFileStats.push({ fileName, total: 0, translated: 0, hasError: true });
            localBdatResults.push({ name: fileName, data: new Uint8Array(buf) });
          }
        }
        // Yield to UI between batches
        await new Promise(r => setTimeout(r, 0));
      }

        // Update stats state so UI can display per-file breakdown
        setBdatFileStats(newBdatFileStats);
      }
      
      // Handle MSBT and JSON BDAT files via server
      if (hasMsbt || hasBdat) {
        const formData = new FormData();
        if (hasMsbt) {
          for (let i = 0; i < msbtFileNames!.length; i++) {
            const name = msbtFileNames![i];
            const buf = msbtFiles![name];
            if (buf) formData.append(`msbt_${i}`, new File([new Uint8Array(buf)], name));
          }
        }
        if (hasBdat) {
          for (let i = 0; i < bdatFileNames!.length; i++) {
            const name = bdatFileNames![i];
            const text = bdatFiles![name];
            if (text) formData.append(`bdat_${i}`, new File([text], name, { type: 'application/json' }));
          }
        }
        
        const nonEmptyTranslations: Record<string, string> = {};
        for (const [k, v] of Object.entries(currentState.translations)) { if (v.trim()) nonEmptyTranslations[k] = v; }

        // Auto Arabic processing before build
        let autoProcessedCountMsbt = 0;
        for (const [key, value] of Object.entries(nonEmptyTranslations)) {
          if (!value?.trim()) continue;
          if (hasArabicPresentationForms(value)) continue;
          if (!hasArabicCharsProcessing(value)) continue;
          nonEmptyTranslations[key] = processArabicText(value, { arabicNumerals, mirrorPunct: mirrorPunctuation });
          autoProcessedCountMsbt++;
        }
        if (autoProcessedCountMsbt > 0) {
          setBuildProgress(`âœ… ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© ${autoProcessedCountMsbt} Ù†Øµ Ø¹Ø±Ø¨ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹...`);
          await new Promise(r => setTimeout(r, 800));
        }
        
        // Auto-fix damaged tags before build
        for (const entry of currentState.entries) {
          if (!/[\uFFF9-\uFFFC\uE000-\uE0FF]/.test(entry.original)) continue;
          const key = `${entry.msbtFile}:${entry.index}`;
          const trans = nonEmptyTranslations[key];
          if (!trans) continue;
          const origTagCount = (entry.original.match(/[\uFFF9-\uFFFC\uE000-\uE0FF]/g) || []).length;
          const transTagCount = (trans.match(/[\uFFF9-\uFFFC\uE000-\uE0FF]/g) || []).length;
          if (transTagCount < origTagCount) {
            nonEmptyTranslations[key] = restoreTagsLocally(entry.original, trans);
          }
        }
        
        formData.append("translations", JSON.stringify(nonEmptyTranslations));
        formData.append("protectedEntries", JSON.stringify(Array.from(currentState.protectedEntries || [])));
        if (arabicNumerals) formData.append("arabicNumerals", "true");
        if (mirrorPunctuation) formData.append("mirrorPunctuation", "true");
        
        setBuildProgress("Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...");
        const supabaseUrl = import.meta.env.VITE_SUPABASE_URL;
        const supabaseKey = import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY;
        const response = await fetch(`${supabaseUrl}/functions/v1/arabize-xenoblade?mode=build`, {
          method: 'POST',
          headers: { 'Authorization': `Bearer ${supabaseKey}`, 'apikey': supabaseKey },
          body: formData,
        });
        if (!response.ok) {
          const ct = response.headers.get('content-type') || '';
          if (ct.includes('json')) { const err = await response.json(); throw new Error(err.error || `Ø®Ø·Ø£ ${response.status}`); }
          throw new Error(`Ø®Ø·Ø£ ${response.status}`);
        }
        setBuildProgress("ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù...");
        const blob = await response.blob();
        const modifiedCount = parseInt(response.headers.get('X-Modified-Count') || '0') + localModifiedCount;
        
        // Pack everything into a single ZIP (server ZIP + local BDAT results)
        if (localBdatResults.length > 0) {
          setBuildProgress(`Ø¯Ù…Ø¬ ${localBdatResults.length} Ù…Ù„Ù BDAT Ù…Ø¹ Ù…Ù„ÙØ§Øª MSBT ÙÙŠ ZIP ÙˆØ§Ø­Ø¯...`);
          const JSZip = (await import("jszip")).default;
          // Load the server ZIP so we can merge it
          const serverZip = await JSZip.loadAsync(blob);
          for (const result of localBdatResults) {
            const cleanName = result.name.replace(/\.(txt|bin)$/i, "");
            const finalName = cleanName.endsWith(".bdat") ? cleanName : cleanName + ".bdat";
            serverZip.file(finalName, result.data);
          }
          const mergedBlob = await serverZip.generateAsync({ type: "blob", compression: "DEFLATE", compressionOptions: { level: 6 } });
          const mergedUrl = URL.createObjectURL(mergedBlob);
          const a = document.createElement("a");
          a.href = mergedUrl;
          a.download = "xenoblade_arabized.zip";
          a.click();
          URL.revokeObjectURL(mergedUrl);
          const overflowSummary = allOverflowErrors.length > 0
            ? ` âš ï¸ ${allOverflowErrors.length} Ù†Øµ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¬Ù… ÙˆØªÙ… ØªØ®Ø·ÙŠÙ‡`
            : '';
          setBuildProgress(`âœ… ØªÙ… Ø¨Ù†Ø¬Ø§Ø­! ØªÙ… ØªØ¹Ø¯ÙŠÙ„ ${modifiedCount} Ù†Øµ â€” Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ ZIP ÙˆØ§Ø­Ø¯${overflowSummary}`);
        } else {
          const blobUrl = URL.createObjectURL(blob);
          const a = document.createElement("a");
          a.href = blobUrl;
          a.download = "xenoblade_arabized.zip";
          a.click();
          setBuildProgress(`âœ… ØªÙ… Ø¨Ù†Ø¬Ø§Ø­! ØªÙ… ØªØ¹Ø¯ÙŠÙ„ ${modifiedCount} Ù†Øµ â€” Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ù…Ù„Ù ZIP`);
        }
      } else if (localBdatResults.length > 0) {
        // Only binary BDAT files â†’ pack ALL into a single ZIP
        setBuildProgress(`ØªØ¬Ù…ÙŠØ¹ ${localBdatResults.length} Ù…Ù„Ù BDAT ÙÙŠ ZIP...`);
        const JSZip = (await import("jszip")).default;
        const zip = new JSZip();
        for (const result of localBdatResults) {
          const cleanName = result.name.replace(/\.(txt|bin)$/i, "");
          const finalName = cleanName.endsWith(".bdat") ? cleanName : cleanName + ".bdat";
          zip.file(finalName, result.data);
        }
        const zipBlob = await zip.generateAsync({ type: "blob", compression: "DEFLATE", compressionOptions: { level: 6 } });
        const zipUrl = URL.createObjectURL(zipBlob);
        const a = document.createElement("a");
        a.href = zipUrl;
        a.download = "xenoblade_arabized_bdat.zip";
        a.click();
        URL.revokeObjectURL(zipUrl);
        const overflowSummary = allOverflowErrors.length > 0
          ? ` âš ï¸ ${allOverflowErrors.length} Ù†Øµ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø£ØµÙ„ÙŠ ÙˆØªÙ… ØªØ®Ø·ÙŠÙ‡`
          : '';
        setBuildProgress(`âœ… ØªÙ… Ø¨Ù†Ø¬Ø§Ø­! ${localBdatResults.length} Ù…Ù„Ù BDAT ÙÙŠ ZIP â€” ØªÙ… ØªØ·Ø¨ÙŠÙ‚ ${localModifiedCount} Ù†Øµ${overflowSummary}`);
      }
      
      // Save translations snapshot for future re-extraction
      try {
        const { idbSet } = await import("@/lib/idb-storage");
        const nonEmpty: Record<string, string> = {};
        for (const [k, v] of Object.entries(currentState.translations || {})) {
          if (v && (v as string).trim()) nonEmpty[k] = v as string;
        }
        if (Object.keys(nonEmpty).length > 0) {
          await idbSet("buildTranslations", nonEmpty);
        }
      } catch (e) {
        console.warn("Could not save build translations snapshot:", e);
      }

      setBuilding(false);
    } catch (err) {
      setBuildProgress(`âŒ ${err instanceof Error ? err.message : 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'}`);
      setBuilding(false);
    }
  };

  const handleCheckIntegrity = async () => {
    const currentState = stateRef.current;
    if (!currentState) return;
    setCheckingIntegrity(true);
    setShowIntegrityDialog(true);

    try {
      const { idbGet } = await import("@/lib/idb-storage");
      const bdatBinaryFiles = await idbGet<Record<string, ArrayBuffer>>("editorBdatBinaryFiles");
      const bdatBinaryFileNames = await idbGet<string[]>("editorBdatBinaryFileNames");

      // All translated (non-empty) keys
      const allTransKeys = Object.keys(currentState.translations).filter(k => currentState.translations[k]?.trim());
      // All entry keys (including untranslated) â€” used to count total extracted strings per file
      const allEntryKeys = currentState.entries
        ? currentState.entries.map(e => `${e.msbtFile}:${e.index}`)
        : Object.keys(currentState.translations);

      // Collect unique filenames from entry keys + translated keys
      const newFormatFiles = new Set<string>();
      const oldFormatFiles = new Set<string>();

      const collectFileNames = (keys: string[]) => {
        for (const key of keys) {
          if (key.startsWith('bdat-bin:')) {
            const parts = key.split(':');
            if (parts.length >= 2) newFormatFiles.add(parts[1]);
          } else if (key.startsWith('bdat:')) {
            const parts = key.split(':');
            if (parts.length >= 2) oldFormatFiles.add(parts[1]);
          }
        }
      };
      collectFileNames(allEntryKeys);
      collectFileNames(allTransKeys);

      const allFileNames = new Set([
        ...Array.from(newFormatFiles),
        ...Array.from(oldFormatFiles),
        ...(bdatBinaryFileNames || []),
      ]);

      const files: IntegrityCheckResult['files'] = [];
      let totalWillApply = 0;
      let totalOrphaned = 0;
      let hasLegacy = false;

      for (const fileName of Array.from(allFileNames)) {
        const fileExists = !!(bdatBinaryFiles && bdatBinaryFiles[fileName]);
        const isLegacyFormat = oldFormatFiles.has(fileName) && !newFormatFiles.has(fileName);
        if (isLegacyFormat) hasLegacy = true;

        const prefix = `bdat-bin:${fileName}:`;

        // Count translated (non-empty) for this file
        const matched = allTransKeys.filter(k => k.startsWith(prefix)).length;

        // Count total entries loaded for this file (translated + untranslated)
        const totalLoaded = allEntryKeys.filter(k => k.startsWith(prefix)).length;

        // Count orphaned old-format keys
        const oldPrefix = `bdat:${fileName}:`;
        const orphanedCount = (!fileExists && isLegacyFormat)
          ? allTransKeys.filter(k => k.startsWith(oldPrefix)).length
          : 0;

        // Total = from loaded entries; fallback to re-parsing IDB file
        let total = totalLoaded;
        if (total === 0 && fileExists && bdatBinaryFiles![fileName]) {
          try {
            const { parseBdatFile, extractBdatStrings } = await import("@/lib/bdat-parser");
            const { unhashLabel } = await import("@/lib/bdat-hash-dictionary");
            const data = new Uint8Array(bdatBinaryFiles![fileName]);
            const bdatFile = parseBdatFile(data, unhashLabel);
            total = extractBdatStrings(bdatFile, fileName).length;
          } catch { total = 0; }
        }

        files.push({ fileName, matched, total, orphaned: orphanedCount, isLegacyFormat, fileExists });

        if (fileExists && !isLegacyFormat) totalWillApply += matched;
        if (!fileExists || isLegacyFormat) totalOrphaned += isLegacyFormat
          ? allTransKeys.filter(k => k.startsWith(`bdat:${fileName}:`)).length
          : 0;
      }

      // Count MSBT/other translated entries too
      const msbtTranslated = allTransKeys.filter(k => !k.startsWith('bdat-bin:') && !k.startsWith('bdat:')).length;
      if (msbtTranslated > 0) totalWillApply += msbtTranslated;

      const isHealthy = files.length > 0
        && !hasLegacy
        && files.every(f => f.fileExists)
        && files.some(f => f.matched > 0);

      setIntegrityResult({
        files: files.sort((a, b) => b.matched - a.matched),
        willApply: totalWillApply,
        orphaned: totalOrphaned,
        hasLegacy,
        isHealthy,
      });
    } catch (e) {
      console.error('[INTEGRITY]', e);
      setIntegrityResult({ files: [], willApply: 0, orphaned: 0, hasLegacy: false, isHealthy: false });
    } finally {
      setCheckingIntegrity(false);
    }
  };

  const handleBuild = async () => {
    const currentState = stateRef.current;
    if (!currentState) return;
    setShowBuildConfirm(false);
    // Force-save before build
    if (forceSaveRef?.current) {
      await forceSaveRef.current();
    }
    const isXenoblade = gameType === "xenoblade";
    
    if (isXenoblade) {
      return handleBuildXenoblade();
    }
    
    const langBuf = await idbGet<ArrayBuffer>("editorLangFile");
    const dictBuf = await idbGet<ArrayBuffer>("editorDictFile");
    const langFileName = (await idbGet<string>("editorLangFileName")) || "output.zs";
    if (!langBuf) { setBuildProgress("âŒ Ù…Ù„Ù Ø§Ù„Ù„ØºØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª."); return; }
    setBuilding(true); setBuildProgress("ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØªØ±Ø¬Ù…Ø§Øª...");
    try {
      const formData = new FormData();
      formData.append("langFile", new File([new Uint8Array(langBuf)], langFileName));
      if (dictBuf) formData.append("dictFile", new File([new Uint8Array(dictBuf)], (await idbGet<string>("editorDictFileName")) || "ZsDic.pack.zs"));
      const nonEmptyTranslations: Record<string, string> = {};
      for (const [k, v] of Object.entries(currentState.translations)) { if (v.trim()) nonEmptyTranslations[k] = v; }

      // Auto-fix damaged tags before build
      let tagFixCount = 0;
      let tagSkipCount = 0;
      let tagOkCount = 0;
      for (const entry of currentState.entries) {
        if (!hasTechnicalTags(entry.original)) continue;
        const key = `${entry.msbtFile}:${entry.index}`;
        const trans = nonEmptyTranslations[key];
        if (!trans) continue;
        const origTagCount = (entry.original.match(/[\uFFF9-\uFFFC\uE000-\uE0FF]/g) || []).length;
        const transTagCount = (trans.match(/[\uFFF9-\uFFFC\uE000-\uE0FF]/g) || []).length;
        if (transTagCount < origTagCount) {
          const fixed = restoreTagsLocally(entry.original, trans);
          nonEmptyTranslations[key] = fixed;
          tagFixCount++;
          // Log DoCommand/LayoutMsg entries for debugging
          if (entry.msbtFile.includes('DoCommand') || entry.msbtFile.includes('Pouch')) {
            const fixedTagCount = (fixed.match(/[\uFFF9-\uFFFC\uE000-\uE0FF]/g) || []).length;
            console.log(`[TAG-FIX] ${key}: orig=${origTagCount} tags, trans=${transTagCount} tags, fixed=${fixedTagCount} tags`);
            console.log(`[TAG-FIX] Original: ${[...entry.original.substring(0, 30)].map(c => c.charCodeAt(0).toString(16).padStart(4,'0')).join(' ')}`);
            console.log(`[TAG-FIX] Fixed: ${[...fixed.substring(0, 30)].map(c => c.charCodeAt(0).toString(16).padStart(4,'0')).join(' ')}`);
          }
        } else {
          tagOkCount++;
        }
      }
      console.log(`[BUILD-TAGS] Fixed: ${tagFixCount}, Already OK: ${tagOkCount}, Skipped(no tags): ${tagSkipCount}`);
      
      // Validate translations size
      const translationsJson = JSON.stringify(nonEmptyTranslations);
      const translationsSizeKB = Math.round(translationsJson.length / 1024);
      console.log(`[BUILD] Total translations being sent: ${Object.keys(nonEmptyTranslations).length}`);
      console.log(`[BUILD] Translations JSON size: ${translationsSizeKB} KB`);
      console.log('[BUILD] Protected entries:', Array.from(currentState.protectedEntries || []).length);
      console.log('[BUILD] Sample keys:', Object.keys(nonEmptyTranslations).slice(0, 10));
      
      if (translationsSizeKB > 5000) {
        console.warn(`[BUILD] âš ï¸ Translations JSON is very large (${translationsSizeKB} KB). This may cause issues.`);
      }
      
      formData.append("translations", JSON.stringify(nonEmptyTranslations));
      formData.append("protectedEntries", JSON.stringify(Array.from(currentState.protectedEntries || [])));
      if (arabicNumerals) formData.append("arabicNumerals", "true");
      if (mirrorPunctuation) formData.append("mirrorPunctuation", "true");
      setBuildProgress("Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...");
      const supabaseUrl = import.meta.env.VITE_SUPABASE_URL;
      const supabaseKey = import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY;
      const response = await fetch(`${supabaseUrl}/functions/v1/arabize?mode=build`, {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${supabaseKey}`, 'apikey': supabaseKey },
        body: formData,
      });
      if (!response.ok) {
        const ct = response.headers.get('content-type') || '';
        if (ct.includes('json')) { const err = await response.json(); throw new Error(err.error || `Ø®Ø·Ø£ ${response.status}`); }
        throw new Error(`Ø®Ø·Ø£ ${response.status}`);
      }
      setBuildProgress("ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù...");
      const blob = await response.blob();
      const blobUrl = URL.createObjectURL(blob);
      const modifiedCount = parseInt(response.headers.get('X-Modified-Count') || '0');
      const expandedCount = parseInt(response.headers.get('X-Expanded-Count') || '0');
      const fileSize = parseInt(response.headers.get('X-File-Size') || '0');
      const compressedSize = response.headers.get('X-Compressed-Size');
      
      console.log('[BUILD] Response headers - Modified:', response.headers.get('X-Modified-Count'), 'Expanded:', response.headers.get('X-Expanded-Count'));
      
      let buildStatsData: BuildStats | null = null;
      try { buildStatsData = JSON.parse(decodeURIComponent(response.headers.get('X-Build-Stats') || '{}')); } catch {}
      const a = document.createElement("a");
      a.href = blobUrl;
      a.download = `arabized_${langFileName}`;
      a.click();
      const expandedMsg = expandedCount > 0 ? ` (${expandedCount} ØªÙ… ØªÙˆØ³ÙŠØ¹Ù‡Ø§ ğŸ“)` : '';
      setBuildProgress(`âœ… ØªÙ… Ø¨Ù†Ø¬Ø§Ø­! ØªÙ… ØªØ¹Ø¯ÙŠÙ„ ${modifiedCount} Ù†Øµ${expandedMsg}`);
      setBuildStats({
        modifiedCount,
        expandedCount,
        fileSize,
        compressedSize: compressedSize ? parseInt(compressedSize) : undefined,
        avgBytePercent: buildStatsData?.avgBytePercent || 0,
        maxBytePercent: buildStatsData?.maxBytePercent || 0,
        longest: buildStatsData?.longest || null,
        shortest: buildStatsData?.shortest || null,
        categories: buildStatsData?.categories || {},
      });
      setBuilding(false);
    } catch (err) {
      setBuildProgress(`âŒ ${err instanceof Error ? err.message : 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'}`);
      setBuilding(false);
    }
  };

  const dismissBuildProgress = () => { setBuildProgress(""); };

  return {
    building,
    buildProgress,
    dismissBuildProgress,
    applyingArabic,
    buildStats,
    setBuildStats,
    buildPreview,
    showBuildConfirm,
    setShowBuildConfirm,
    bdatFileStats,
    integrityResult,
    showIntegrityDialog,
    setShowIntegrityDialog,
    checkingIntegrity,
    handleApplyArabicProcessing,
    handleUndoArabicProcessing,
    handlePreBuild,
    handleBuild,
    handleCheckIntegrity,
  };
}

